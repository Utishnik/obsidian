Зная как работали [[gpt]] 3 я щас подозреваю что в [[chat gpt]] 4o юзается(она типо думает а не сразу генерит) что то типо [[backtracking]]  типо есть еще одна [[подмодель]] например которая ищет протеворечие чтоб [[chat gpt]] не писал почему в самолетах синие стопкраны,она типо пишет это(ну не отправляет этап обдумывания) а вторая модель смотрит нейросеткой как во втором блоке после [[общения векторов]] [[задает вопросы]] своего рода.И так она делает не сразу в конце со всем текстом с частями текста, и как [[backtracking]] отбросает и возвращается к предыдущему недогенерированому тексту, и потом она самой [[gpt]] пишет что ошибка у пользователя стоп краны не такие. Иногда может для этого нужно отрываться от контекста и оценивать как [[блок внимания]] повлиял на это и то на чем обучена [[gpt]] должно что то индифицировать как [[утверждение]] тоесть у самолета красные не синие,и само сообщение должно [[оценится]], например оно может быть генеративным типо представь мир если бы были синей, тут нет ошибки,а если вопрос почему так,то тут уже надо указать на ошибку.Типо например как то индифицировать текст от 0 до 1 например 1 это [[утверждение]] 0 это вообще пофик можно рандомное говорить(точнее не связанное с действительностью),
в случае с самолетом это 1 1*(отрыв [[контекстом]] тоесть разница между фактом) - разница огромна.
